{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quazicynical/DeepSc2/blob/main/deepsc8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvcCuhBobg5M",
        "outputId": "634eb146-80ed-4cc5-af73-c8e96a9232b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.38.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install portalocker\n",
        "!pip install -U torchdata\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xCW1YXwDblwN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "import math\n",
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "94cngNZVboYe"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from typing import Iterable, List\n",
        "\n",
        "\n",
        "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
        "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
        "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'de'\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xvSuipwRbqd4"
      },
      "outputs": [],
      "source": [
        "token_transform[SRC_LANGUAGE] = get_tokenizer('basic_english', language='en')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    # Training data Iterator\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xNFXUA2SbvSp"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QwCiW9TBbyU9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.datasets import STSB\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "vQRinefVb0K8"
      },
      "outputs": [],
      "source": [
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SNR_to_noise(snr):\n",
        "    snr = 10 ** (snr / 10)\n",
        "    noise_std = 1 / np.sqrt(2 * snr)\n",
        "\n",
        "    return noise_std"
      ],
      "metadata": {
        "id": "bY7Yh9ie4t8U"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AWGN(Tx_sig, n_var):\n",
        "    Rx_sig = Tx_sig + torch.normal(0, n_var, size=Tx_sig.shape).to(DEVICE)\n",
        "    return Rx_sig\n",
        "\n",
        "def Rayleigh(Tx_sig, n_var):\n",
        "    shape = Tx_sig.shape\n",
        "    H_real = torch.normal(0, math.sqrt(1/2), size=[1]).to(DEVICE)\n",
        "    H_imag = torch.normal(0, math.sqrt(1/2), size=[1]).to(DEVICE)\n",
        "    H = torch.Tensor([[H_real, -H_imag], [H_imag, H_real]]).to(DEVICE)\n",
        "    Tx_sig = torch.matmul(Tx_sig.view(shape[0], -1, 2), H)\n",
        "    Rx_sig = AWGN(Tx_sig, n_var)\n",
        "    # Channel estimation\n",
        "    Rx_sig = torch.matmul(Rx_sig, torch.inverse(H)).view(shape)\n",
        "\n",
        "    return Rx_sig\n",
        "\n",
        "noise_std = np.random.uniform(SNR_to_noise(5), SNR_to_noise(10), size=(1))"
      ],
      "metadata": {
        "id": "UoFlEJI13-eY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "a3WRHUmmcRS7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "class Compressor(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.dense_encoder = nn.Sequential(nn.Linear(512, 256),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(256, 128),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(128, 64))\n",
        "      self.dense_decoder = nn.Sequential(nn.Linear(64, 128),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(128, 256),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(256, 512))\n",
        "    def forward(self, tensor):\n",
        "      tensor = self.dense_encoder(tensor)\n",
        "      tensor = PowerNormalize(tensor)\n",
        "      noise_std = np.random.uniform(SNR_to_noise(5), SNR_to_noise(10), size=(1))\n",
        "\n",
        "      noise = torch.rand(tensor.shape)\n",
        "      noise = noise.to(DEVICE)\n",
        "      tensor = Rayleigh(tensor,noise_std[0])\n",
        "\n",
        "      logits = self.dense_decoder(tensor)\n",
        "      return logits\n",
        "\n",
        "def PowerNormalize(x):\n",
        "\n",
        "    x_square = torch.mul(x, x)\n",
        "    power = torch.mean(x_square).sqrt()\n",
        "    if power > 1:\n",
        "        x = torch.div(x, power)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vhNGrjRXb14w"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        #self.transformer = Transformer(d_model=emb_size,\n",
        "        #                               nhead=nhead,\n",
        "        #                               num_encoder_layers=num_encoder_layers,\n",
        "        #                               num_decoder_layers=num_decoder_layers,\n",
        "        #                               dim_feedforward=dim_feedforward,\n",
        "        #                               dropout=dropout)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout), num_layers=3)\n",
        "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(nn.TransformerDecoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout), num_layers=3)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "        self.compressor = Compressor()\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        out1 = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
        "        out3 = self.compressor(out1)\n",
        "        out2 = self.transformer_decoder(tgt_emb, out3, tgt_mask, None,\n",
        "                                 tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(out2)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer_encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer_decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "vsaoawtfb5YM"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk2D97AQb7mZ",
        "outputId": "eeaa0bae-de8a-4204-eb28-24f017239866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512 # change here\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, SRC_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kQijVZKLb98x"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in train_dataloader:\n",
        "        tgt = src\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(train_dataloader))\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        tgt = src\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(val_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVRcFJQ8cGJO",
        "outputId": "d1ae2f22-fc9d-4adb-afee-9727528b6d5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 0.319, Val loss: 0.448, Epoch time = 42.536s\n",
            "Epoch: 2, Train loss: 0.291, Val loss: 0.823, Epoch time = 43.391s\n",
            "Epoch: 3, Train loss: 0.247, Val loss: 0.579, Epoch time = 42.211s\n",
            "Epoch: 4, Train loss: 0.278, Val loss: 0.413, Epoch time = 42.548s\n",
            "Epoch: 5, Train loss: 0.198, Val loss: 0.401, Epoch time = 43.132s\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 5 #modify\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "_mzN2AGAjFNZ"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    memory = memory.to(DEVICE)\n",
        "    memory = model.compressor(memory)\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "def translate(model: torch.nn.Module, src_sentence: str):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
        "    return \" \".join(vocab_transform[SRC_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src = text_transform[SRC_LANGUAGE](\"a man eating beans\").view(-1, 1)\n",
        "src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImUrmzOdBPf7",
        "outputId": "04d5eebd-d66c-413b-9ab9-9bfb368f0b3a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   2],\n",
              "        [   4],\n",
              "        [   9],\n",
              "        [ 186],\n",
              "        [3865],\n",
              "        [   3]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADrj-M9JjSQR",
        "outputId": "146c5f7c-51ba-4934-9040-3492374f4436"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " a man eating hotdogs \n"
          ]
        }
      ],
      "source": [
        "print(translate(transformer, \"a man eating beans\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        },
        "id": "K8eWjHI6O-ga",
        "outputId": "000edab8-cd30-41ed-e415-3a8592ec3c9b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name sentence-transformers/all-MiniLM-L6-v2. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like sentence-transformers/all-MiniLM-L6-v2 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 503 Server Error: Service Temporarily Unavailable for url: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1237\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1238\u001b[0;31m                 metadata = get_hf_file_metadata(\n\u001b[0m\u001b[1;32m   1239\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Retrieve metadata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     r = _request_wrapper(\n\u001b[0m\u001b[1;32m   1632\u001b[0m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"HEAD\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfollow_relative_redirects\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         response = _request_wrapper(\n\u001b[0m\u001b[1;32m    386\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m     \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    332\u001b[0m         \u001b[0;31m# as well (request id and/or server error message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m: 503 Server Error: Service Temporarily Unavailable for url: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 398\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    399\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;31m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             raise LocalEntryNotFoundError(\n\u001b[0m\u001b[1;32m   1372\u001b[0m                 \u001b[0;34m\"An error happened while trying to locate the file on the Hub and we cannot find the requested files\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-36042aa3a3cd>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all-MiniLM-L6-v2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, cache_folder, trust_remote_code, revision, token, use_auth_token, truncate_dim)\u001b[0m\n\u001b[1;32m    203\u001b[0m                 )\n\u001b[1;32m    204\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                 modules = self._load_auto_model(\n\u001b[0m\u001b[1;32m    206\u001b[0m                     \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                     \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36m_load_auto_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code)\u001b[0m\n\u001b[1;32m   1195\u001b[0m             )\n\u001b[1;32m   1196\u001b[0m         )\n\u001b[0;32m-> 1197\u001b[0;31m         transformer_model = Transformer(\n\u001b[0m\u001b[1;32m   1198\u001b[0m             \u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1199\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sentence_transformers/models/Transformer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_name_or_path, max_seq_length, model_args, cache_dir, tokenizer_args, do_lower_case, tokenizer_name_or_path)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1109\u001b[0m         \u001b[0mcode_revision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"code_revision\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munused_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPretrainedConfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0mhas_remote_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"auto_map\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"AutoConfig\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"auto_map\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0mhas_local_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model_type\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model_type\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCONFIG_MAPPING\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36mget_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0moriginal_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# Get config dict associated with the base config file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m         \u001b[0mconfig_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_config_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0moriginal_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\u001b[0m in \u001b[0;36m_get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;31m# Load from local folder or from cache or download from model Hub and cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m                 resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    689\u001b[0m                     \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m                     \u001b[0mconfiguration_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    439\u001b[0m         ):\n\u001b[1;32m    440\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresolved_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    442\u001b[0m             \u001b[0;34mf\"We couldn't connect to '{HUGGINGFACE_CO_RESOLVE_ENDPOINT}' to load this file, couldn't find it in the\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0;34mf\" cached files and it looks like {path_or_repo_id} is not the path to a directory containing a file named\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like sentence-transformers/all-MiniLM-L6-v2 is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "YB1Iu9o0nAJb"
      },
      "outputs": [],
      "source": [
        "sentences1 = [\n",
        "    \"The cat sits outside.\",\n",
        "    \"A man is playing guitar\",\n",
        "    \"A man wearing a coat\",\n",
        "    \"The dog ran very fast\",\n",
        "    \"The boy had a party\",\n",
        "    \"A woman eating a ice cream\"\n",
        "]\n",
        "\n",
        "s = []\n",
        "i = 0.01\n",
        "while(i<1):\n",
        "  #print(i)\n",
        "  sentences2 = [\n",
        "    translate(transformer, \"The cat sits outside.\"),\n",
        "    translate(transformer, \"A man is playing guitar\"),\n",
        "    translate(transformer, \"A man wearing a coat\"),\n",
        "    translate(transformer, \"The dog ran very fast\"),\n",
        "    translate(transformer, \"The boy had a party\"),\n",
        "    translate(transformer, \"A woman eating a ice cream\")\n",
        "  ]\n",
        "  #print(sentences2[0])\n",
        "  embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
        "  embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
        "  l = []\n",
        "\n",
        "  cosine_scores = Tensor.cpu(util.cos_sim(embeddings1, embeddings2))\n",
        "  for j in range(6):\n",
        "    l.append(cosine_scores[j][j])\n",
        "  s.append(sum(l)/6)\n",
        "  i+=0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "zy0DltYPPL6d",
        "outputId": "684456ab-3830-4d9d-a369-ceb3968fe1ee"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x78c7787b8d90>]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "class NodeTree(object):\n",
        "    def _init_(self, left=None, right=None):\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "    def children(self):\n",
        "        return self.left, self.right\n",
        "\n",
        "    def _str_(self):\n",
        "        return self.left, self.right\n",
        "\n",
        "\n",
        "def huffman_code_tree(node, binString=''):\n",
        "    '''\n",
        "    Function to find Huffman Code\n",
        "    '''\n",
        "    if type(node) is str:\n",
        "        return {node: binString}\n",
        "    (l, r) = node.children()\n",
        "    d = dict()\n",
        "    d.update(huffman_code_tree(l, binString + '0'))\n",
        "    d.update(huffman_code_tree(r, binString + '1'))\n",
        "    return d\n",
        "\n",
        "\n",
        "def make_tree(nodes):\n",
        "    '''\n",
        "    Function to make tree\n",
        "    :param nodes: Nodes\n",
        "    :return: Root of the tree\n",
        "    '''\n",
        "    while len(nodes) > 1:\n",
        "        (key1, c1) = nodes[-1]\n",
        "        (key2, c2) = nodes[-2]\n",
        "        nodes = nodes[:-2]\n",
        "        node = NodeTree()\n",
        "        node.left = key1\n",
        "        node.right = key2\n",
        "        nodes.append((node, c1 + c2))\n",
        "        nodes = sorted(nodes, key=lambda x: x[1], reverse=True)\n",
        "    return nodes[0][0]\n",
        "\n",
        "\n",
        "if (True):\n",
        "    string = 'a man wearing a coat'\n",
        "    freq = dict(Counter(string))\n",
        "    freq = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    node = make_tree(freq)\n",
        "    encoding = huffman_code_tree(node)\n",
        "    for i in encoding:\n",
        "        print(f'{i} : {encoding[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-IpJqWSQQMk",
        "outputId": "c2c3b1e5-f5bd-4281-fc20-fb80fbc44951"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i : 0000\n",
            "r : 0001\n",
            "c : 0010\n",
            "g : 0011\n",
            "  : 01\n",
            "a : 10\n",
            "m : 1100\n",
            "e : 11010\n",
            "w : 11011\n",
            "t : 11100\n",
            "o : 11101\n",
            "n : 1111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in string:\n",
        "  print(encoding[i],end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LftK5M73Q67p",
        "outputId": "45f8d2a2-fafb-4d4e-c276-41cb0c5251b3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100111001011110111011110101000010000111100110110010010111011011100"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reedsolo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_FqcY-mWzOq",
        "outputId": "bad66ff3-9aa9-40b3-97b3-af6227c05cbd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reedsolo\n",
            "  Downloading reedsolo-1.7.0-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: reedsolo\n",
            "Successfully installed reedsolo-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import reedsolo as rsc\n",
        "\n",
        "def encoding(per, msg, n, nsym, gen):\n",
        "    time1 = 0\n",
        "    count = 0\n",
        "\n",
        "    rs.init_tables(0x11d)\n",
        "    while time1 < per:\n",
        "        temp = time.time()\n",
        "        s = rs.rs_encode_msg(msg, nsym, gen=gen[nsym])\n",
        "\n",
        "        time1 += time.time() - temp\n",
        "        count += 1\n",
        "    #print(rs.rs_decode(s, nsym, gen=gen[nsym]))\n",
        "    return s\n",
        "\n",
        "def main():\n",
        "    data = b\"a man wearing a coat\" #This data size is 10MB\n",
        "    n = 8\n",
        "    nsym = 3\n",
        "    period = 10\n",
        "\n",
        "\n",
        "    gen = rs.rs_generator_poly_all(n)\n",
        "    encoding(period, data, 8, 3, gen)\n",
        "    return(gen)"
      ],
      "metadata": {
        "id": "lvC9vB8JW0T6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reedsolo import RSCodec, ReedSolomonError\n",
        "rsc = RSCodec(10)\n",
        "a = rsc.encode(b'100111001011110111011110101000010000111100110110010010111011011100')"
      ],
      "metadata": {
        "id": "Gpyf3S6_fclR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6obHx67Kfv35",
        "outputId": "7190970e-85fa-41f2-cf40-d61f2b05389c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytearray(b'100111001011110111011110101000010000111100110110010010111011011100X\\x9b\\x08\\xbbQX\\x02\\xe4M\\xd3')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = rsc.decode(b'100111001011110111011110101111111111111100110110010010111011011100X\\x9b\\x08\\xbbQX\\x02\\xe4M\\xd3')\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "YBjVBrRhd5xR",
        "outputId": "47360887-b2db-4894-d520-c430b510d42c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ReedSolomonError",
          "evalue": "Too many errors to correct",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReedSolomonError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ec4b04ec24ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'100111001011110111011110101111111111111100110110010010111011011100X\\x9b\\x08\\xbbQX\\x02\\xe4M\\xd3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/reedsolo.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, data, nsym, erase_pos, only_erasures)\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0merase_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merase_pos\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;31m# Decode/repair this chunk!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mrmes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrata_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_correct_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merase_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_erasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_erasures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mdec_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmes\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrecc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/reedsolo.py\u001b[0m in \u001b[0;36mrs_correct_msg\u001b[0;34m(msg_in, nsym, fcr, generator, erase_pos, only_erasures)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mfsynd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_forney_syndromes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merase_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# compute the error locator polynomial using Berlekamp-Massey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0merr_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_find_error_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsynd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merase_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merase_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0;31m# locate the message errors using Chien search (or bruteforce search)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0merr_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_find_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_loc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/reedsolo.py\u001b[0m in \u001b[0;36mrs_find_error_locator\u001b[0;34m(synd, nsym, erase_loc, erase_count)\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0merrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_loc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0merase_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0merase_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnsym\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mReedSolomonError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many errors to correct\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merr_loc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReedSolomonError\u001b[0m: Too many errors to correct"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"100111001011110111011110101000010000111100110110010010111011011100\"\n",
        "length = len(s)\n",
        "import torch\n",
        "noise = torch.rand(1,length)\n",
        "for i in noise[0]:\n",
        "  if(i>0.9):\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYHyp0cqm8wL",
        "outputId": "fb8ba642-2d2a-4bd0-a403-376c13ff42ad"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9740)\n",
            "tensor(0.9719)\n",
            "tensor(0.9479)\n",
            "tensor(0.9224)\n",
            "tensor(0.9146)\n",
            "tensor(0.9768)\n",
            "tensor(0.9738)\n",
            "tensor(0.9521)\n",
            "tensor(0.9852)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(\"hi\")\n",
        "type(len)\n",
        "del len"
      ],
      "metadata": {
        "id": "rpHQtqodp9_u"
      },
      "execution_count": 30,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}