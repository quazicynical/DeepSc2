{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/quazicynical/DeepSc2/blob/main/deepsc8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvcCuhBobg5M",
        "outputId": "147a07d4-b90b-4442-b73d-bfa842f9218b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting portalocker\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: portalocker\n",
            "Successfully installed portalocker-2.8.2\n",
            "Requirement already satisfied: torchdata in /usr/local/lib/python3.10/dist-packages (0.7.1)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.31.0)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.10/dist-packages (from torchdata) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2->torchdata)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2->torchdata) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2->torchdata)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2->torchdata) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2->torchdata) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.7.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Installing collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install portalocker\n",
        "!pip install -U torchdata\n",
        "!pip install -U spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm\n",
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCW1YXwDblwN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Function\n",
        "import math\n",
        "import math\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "from torch.utils.data import dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94cngNZVboYe"
      },
      "outputs": [],
      "source": [
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.datasets import multi30k, Multi30k\n",
        "from typing import Iterable, List\n",
        "\n",
        "\n",
        "# We need to modify the URLs for the dataset since the links to the original dataset are broken\n",
        "# Refer to https://github.com/pytorch/text/issues/1756#issuecomment-1163664163 for more info\n",
        "multi30k.URL[\"train\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/training.tar.gz\"\n",
        "multi30k.URL[\"valid\"] = \"https://raw.githubusercontent.com/neychev/small_DL_repo/master/datasets/Multi30k/validation.tar.gz\"\n",
        "\n",
        "SRC_LANGUAGE = 'en'\n",
        "TGT_LANGUAGE = 'de'\n",
        "\n",
        "# Place-holders\n",
        "token_transform = {}\n",
        "vocab_transform = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvSuipwRbqd4"
      },
      "outputs": [],
      "source": [
        "token_transform[SRC_LANGUAGE] = get_tokenizer('basic_english', language='en')\n",
        "token_transform[TGT_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
        "\n",
        "\n",
        "# helper function to yield list of tokens\n",
        "def yield_tokens(data_iter: Iterable, language: str) -> List[str]:\n",
        "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
        "\n",
        "    for data_sample in data_iter:\n",
        "        yield token_transform[language](data_sample[language_index[language]])\n",
        "\n",
        "# Define special symbols and indices\n",
        "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
        "# Make sure the tokens are in order of their indices to properly insert them in vocab\n",
        "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    # Training data Iterator\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    # Create torchtext's Vocab object\n",
        "    vocab_transform[ln] = build_vocab_from_iterator(yield_tokens(train_iter, ln),\n",
        "                                                    min_freq=1,\n",
        "                                                    specials=special_symbols,\n",
        "                                                    special_first=True)\n",
        "\n",
        "# Set ``UNK_IDX`` as the default index. This index is returned when the token is not found.\n",
        "# If not set, it throws ``RuntimeError`` when the queried token is not found in the Vocabulary.\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "  vocab_transform[ln].set_default_index(UNK_IDX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNFXUA2SbvSp"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# helper function to club together sequential operations\n",
        "def sequential_transforms(*transforms):\n",
        "    def func(txt_input):\n",
        "        for transform in transforms:\n",
        "            txt_input = transform(txt_input)\n",
        "        return txt_input\n",
        "    return func\n",
        "\n",
        "# function to add BOS/EOS and create tensor for input sequence indices\n",
        "def tensor_transform(token_ids: List[int]):\n",
        "    return torch.cat((torch.tensor([BOS_IDX]),\n",
        "                      torch.tensor(token_ids),\n",
        "                      torch.tensor([EOS_IDX])))\n",
        "\n",
        "# ``src`` and ``tgt`` language text transforms to convert raw strings into tensors indices\n",
        "text_transform = {}\n",
        "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
        "    text_transform[ln] = sequential_transforms(token_transform[ln], #Tokenization\n",
        "                                               vocab_transform[ln], #Numericalization\n",
        "                                               tensor_transform) # Add BOS/EOS and create tensor\n",
        "\n",
        "\n",
        "# function to collate data samples into batch tensors\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src_sample, tgt_sample in batch:\n",
        "        src_batch.append(text_transform[SRC_LANGUAGE](src_sample.rstrip(\"\\n\")))\n",
        "        tgt_batch.append(text_transform[TGT_LANGUAGE](tgt_sample.rstrip(\"\\n\")))\n",
        "\n",
        "    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX)\n",
        "    return src_batch, tgt_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwCiW9TBbyU9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchtext.datasets import STSB\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import numpy as np\n",
        "BATCH_SIZE = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQRinefVb0K8"
      },
      "outputs": [],
      "source": [
        "train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def SNR_to_noise(snr):\n",
        "    snr = 10 ** (snr / 10)\n",
        "    noise_std = 1 / np.sqrt(2 * snr)\n",
        "\n",
        "    return noise_std"
      ],
      "metadata": {
        "id": "bY7Yh9ie4t8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AWGN(Tx_sig, n_var):\n",
        "    Rx_sig = Tx_sig + torch.normal(0, n_var, size=Tx_sig.shape).to(DEVICE)\n",
        "    return Rx_sig\n",
        "\n",
        "def Rayleigh(Tx_sig, n_var):\n",
        "    shape = Tx_sig.shape\n",
        "    H_real = torch.normal(0, math.sqrt(1/2), size=[1]).to(DEVICE)\n",
        "    H_imag = torch.normal(0, math.sqrt(1/2), size=[1]).to(DEVICE)\n",
        "    H = torch.Tensor([[H_real, -H_imag], [H_imag, H_real]]).to(DEVICE)\n",
        "    Tx_sig = torch.matmul(Tx_sig.view(shape[0], -1, 2), H)\n",
        "    Rx_sig = AWGN(Tx_sig, n_var)\n",
        "    # Channel estimation\n",
        "    Rx_sig = torch.matmul(Rx_sig, torch.inverse(H)).view(shape)\n",
        "\n",
        "    return Rx_sig\n",
        "\n",
        "noise_std = np.random.uniform(SNR_to_noise(5), SNR_to_noise(10), size=(1))"
      ],
      "metadata": {
        "id": "UoFlEJI13-eY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3WRHUmmcRS7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "class Compressor(nn.Module):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.dense_encoder = nn.Sequential(nn.Linear(512, 256),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(256, 128),\n",
        "                                 nn.ReLU(),\n",
        "                                 nn.Linear(128, 64))\n",
        "      self.dense_decoder = nn.Sequential(nn.Linear(64, 128),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(128, 256),\n",
        "                                         nn.ReLU(),\n",
        "                                         nn.Linear(256, 512))\n",
        "    def forward(self, tensor, nvar):\n",
        "      tensor = self.dense_encoder(tensor)\n",
        "      tensor = PowerNormalize(tensor)\n",
        "      #noise_std = np.random.uniform(SNR_to_noise(5), SNR_to_noise(10), size=(1))\n",
        "\n",
        "      noise = torch.rand(tensor.shape)\n",
        "      noise = noise.to(DEVICE)\n",
        "      tensor = Rayleigh(tensor,nvar)\n",
        "\n",
        "      logits = self.dense_decoder(tensor)\n",
        "      return logits\n",
        "\n",
        "def PowerNormalize(x):\n",
        "\n",
        "    x_square = torch.mul(x, x)\n",
        "    power = torch.mean(x_square).sqrt()\n",
        "    if power > 1:\n",
        "        x = torch.div(x, power)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vhNGrjRXb14w"
      },
      "outputs": [],
      "source": [
        "from torch import Tensor\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import Transformer\n",
        "import math\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# helper Module that adds positional encoding to the token embedding to introduce a notion of word order.\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self,\n",
        "                 emb_size: int,\n",
        "                 dropout: float,\n",
        "                 maxlen: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n",
        "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
        "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
        "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
        "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
        "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('pos_embedding', pos_embedding)\n",
        "\n",
        "    def forward(self, token_embedding: Tensor):\n",
        "        return self.dropout(token_embedding + self.pos_embedding[:token_embedding.size(0), :])\n",
        "\n",
        "# helper Module to convert tensor of input indices into corresponding tensor of token embeddings\n",
        "class TokenEmbedding(nn.Module):\n",
        "    def __init__(self, vocab_size: int, emb_size):\n",
        "        super(TokenEmbedding, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
        "        self.emb_size = emb_size\n",
        "\n",
        "    def forward(self, tokens: Tensor):\n",
        "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n",
        "\n",
        "# Seq2Seq Network\n",
        "class Seq2SeqTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_encoder_layers: int,\n",
        "                 num_decoder_layers: int,\n",
        "                 emb_size: int,\n",
        "                 nhead: int,\n",
        "                 src_vocab_size: int,\n",
        "                 tgt_vocab_size: int,\n",
        "                 dim_feedforward: int = 512,\n",
        "                 dropout: float = 0.1):\n",
        "        super(Seq2SeqTransformer, self).__init__()\n",
        "        #self.transformer = Transformer(d_model=emb_size,\n",
        "        #                               nhead=nhead,\n",
        "        #                               num_encoder_layers=num_encoder_layers,\n",
        "        #                               num_decoder_layers=num_decoder_layers,\n",
        "        #                               dim_feedforward=dim_feedforward,\n",
        "        #                               dropout=dropout)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
        "        self.transformer_encoder = nn.TransformerEncoder(nn.TransformerEncoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout), num_layers=3)\n",
        "        self.decoder_layer = nn.TransformerDecoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout)\n",
        "        self.transformer_decoder = nn.TransformerDecoder(nn.TransformerDecoderLayer(d_model=emb_size, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout), num_layers=3)\n",
        "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
        "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
        "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
        "        self.positional_encoding = PositionalEncoding(\n",
        "            emb_size, dropout=dropout)\n",
        "        self.compressor = Compressor()\n",
        "\n",
        "    def forward(self,\n",
        "                src: Tensor,\n",
        "                trg: Tensor,\n",
        "                src_mask: Tensor,\n",
        "                tgt_mask: Tensor,\n",
        "                src_padding_mask: Tensor,\n",
        "                tgt_padding_mask: Tensor,\n",
        "                memory_key_padding_mask: Tensor):\n",
        "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
        "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
        "        out1 = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
        "        noise_std = np.random.uniform(SNR_to_noise(5), SNR_to_noise(10), size=(1))\n",
        "        out3 = self.compressor(out1, noise_std[0])\n",
        "        out2 = self.transformer_decoder(tgt_emb, out3, tgt_mask, None,\n",
        "                                 tgt_padding_mask, memory_key_padding_mask)\n",
        "        return self.generator(out2)\n",
        "\n",
        "    def encode(self, src: Tensor, src_mask: Tensor):\n",
        "        return self.transformer_encoder(self.positional_encoding(\n",
        "                            self.src_tok_emb(src)), src_mask)\n",
        "\n",
        "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
        "        return self.transformer_decoder(self.positional_encoding(\n",
        "                          self.tgt_tok_emb(tgt)), memory,\n",
        "                          tgt_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsaoawtfb5YM"
      },
      "outputs": [],
      "source": [
        "def generate_square_subsequent_mask(sz):\n",
        "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
        "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
        "    return mask\n",
        "\n",
        "\n",
        "def create_mask(src, tgt):\n",
        "    src_seq_len = src.shape[0]\n",
        "    tgt_seq_len = tgt.shape[0]\n",
        "\n",
        "    tgt_mask = generate_square_subsequent_mask(tgt_seq_len)\n",
        "    src_mask = torch.zeros((src_seq_len, src_seq_len),device=DEVICE).type(torch.bool)\n",
        "\n",
        "    src_padding_mask = (src == PAD_IDX).transpose(0, 1)\n",
        "    tgt_padding_mask = (tgt == PAD_IDX).transpose(0, 1)\n",
        "    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uk2D97AQb7mZ",
        "outputId": "a59b740d-c37a-40fb-afe4-650f37b8af2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:286: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "SRC_VOCAB_SIZE = len(vocab_transform[SRC_LANGUAGE])\n",
        "TGT_VOCAB_SIZE = len(vocab_transform[TGT_LANGUAGE])\n",
        "EMB_SIZE = 512 # change here\n",
        "NHEAD = 8\n",
        "FFN_HID_DIM = 512\n",
        "BATCH_SIZE = 128\n",
        "NUM_ENCODER_LAYERS = 3\n",
        "NUM_DECODER_LAYERS = 3\n",
        "\n",
        "transformer = Seq2SeqTransformer(NUM_ENCODER_LAYERS, NUM_DECODER_LAYERS, EMB_SIZE,\n",
        "                                 NHEAD, SRC_VOCAB_SIZE, SRC_VOCAB_SIZE, FFN_HID_DIM)\n",
        "\n",
        "for p in transformer.parameters():\n",
        "    if p.dim() > 1:\n",
        "        nn.init.xavier_uniform_(p)\n",
        "\n",
        "transformer = transformer.to(DEVICE)\n",
        "\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQijVZKLb98x"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
        "\n",
        "optimizer = torch.optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
        "def train_epoch(model, optimizer):\n",
        "    model.train()\n",
        "    losses = 0\n",
        "    train_iter = Multi30k(split='train', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    train_dataloader = DataLoader(train_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in train_dataloader:\n",
        "        tgt = src\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(train_dataloader))\n",
        "\n",
        "\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "    losses = 0\n",
        "\n",
        "    val_iter = Multi30k(split='valid', language_pair=(SRC_LANGUAGE, TGT_LANGUAGE))\n",
        "    val_dataloader = DataLoader(val_iter, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
        "\n",
        "    for src, tgt in val_dataloader:\n",
        "        tgt = src\n",
        "        src = src.to(DEVICE)\n",
        "        tgt = tgt.to(DEVICE)\n",
        "\n",
        "        tgt_input = tgt[:-1, :]\n",
        "\n",
        "        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt_input)\n",
        "\n",
        "        logits = model(src, tgt_input, src_mask, tgt_mask,src_padding_mask, tgt_padding_mask, src_padding_mask)\n",
        "\n",
        "        tgt_out = tgt[1:, :]\n",
        "        loss = loss_fn(logits.reshape(-1, logits.shape[-1]), tgt_out.reshape(-1))\n",
        "        losses += loss.item()\n",
        "\n",
        "    return losses / len(list(val_dataloader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVRcFJQ8cGJO",
        "outputId": "41df1f3a-42aa-47e8-a779-b409af4f3a3a"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:5109: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/datapipes/iter/combining.py:337: UserWarning: Some child DataPipes are not exhausted when __iter__ is called. We are resetting the buffer and each child DataPipe will read from the start again.\n",
            "  warnings.warn(\"Some child DataPipes are not exhausted when __iter__ is called. We are resetting \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Train loss: 5.240, Val loss: 4.123, Epoch time = 42.156s\n",
            "Epoch: 2, Train loss: 3.904, Val loss: 3.627, Epoch time = 42.843s\n",
            "Epoch: 3, Train loss: 3.399, Val loss: 3.087, Epoch time = 42.290s\n",
            "Epoch: 4, Train loss: 2.863, Val loss: 2.716, Epoch time = 43.513s\n",
            "Epoch: 5, Train loss: 2.393, Val loss: 2.047, Epoch time = 42.546s\n",
            "Epoch: 6, Train loss: 1.970, Val loss: 1.704, Epoch time = 43.249s\n",
            "Epoch: 7, Train loss: 1.651, Val loss: 1.574, Epoch time = 43.636s\n",
            "Epoch: 8, Train loss: 1.404, Val loss: 1.180, Epoch time = 42.612s\n",
            "Epoch: 9, Train loss: 1.132, Val loss: 1.024, Epoch time = 43.319s\n",
            "Epoch: 10, Train loss: 1.003, Val loss: 2.078, Epoch time = 42.413s\n",
            "Epoch: 11, Train loss: 0.853, Val loss: 0.826, Epoch time = 42.637s\n",
            "Epoch: 12, Train loss: 0.762, Val loss: 0.692, Epoch time = 43.410s\n",
            "Epoch: 13, Train loss: 0.723, Val loss: 0.614, Epoch time = 42.799s\n",
            "Epoch: 14, Train loss: 0.624, Val loss: 0.583, Epoch time = 43.199s\n",
            "Epoch: 15, Train loss: 0.521, Val loss: 0.543, Epoch time = 42.463s\n",
            "Epoch: 16, Train loss: 0.598, Val loss: 0.530, Epoch time = 42.712s\n",
            "Epoch: 17, Train loss: 0.438, Val loss: 0.474, Epoch time = 43.153s\n",
            "Epoch: 18, Train loss: 0.470, Val loss: 0.506, Epoch time = 42.491s\n",
            "Epoch: 19, Train loss: 0.392, Val loss: 0.454, Epoch time = 42.367s\n",
            "Epoch: 20, Train loss: 0.392, Val loss: 0.428, Epoch time = 43.131s\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "NUM_EPOCHS = 20 #modify\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train_epoch(transformer, optimizer)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(transformer)\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \"f\"Epoch time = {(end_time - start_time):.3f}s\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mzN2AGAjFNZ"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src, src_mask, max_len, start_symbol, nvar):\n",
        "    src = src.to(DEVICE)\n",
        "    src_mask = src_mask.to(DEVICE)\n",
        "\n",
        "    memory = model.encode(src, src_mask)\n",
        "    memory = memory.to(DEVICE)\n",
        "    #noise_std = np.random.uniform(SNR_to_noise(5), SNR_to_noise(10), size=(1))\n",
        "    memory = model.compressor(memory, SNR_to_noise(nvar))\n",
        "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
        "    for i in range(max_len-1):\n",
        "        tgt_mask = (generate_square_subsequent_mask(ys.size(0))\n",
        "                    .type(torch.bool)).to(DEVICE)\n",
        "        out = model.decode(ys, memory, tgt_mask)\n",
        "        out = out.transpose(0, 1)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.item()\n",
        "\n",
        "        ys = torch.cat([ys,\n",
        "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
        "        if next_word == EOS_IDX:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "def translate(model: torch.nn.Module, src_sentence: str, nvar):\n",
        "    model.eval()\n",
        "    src = text_transform[SRC_LANGUAGE](src_sentence).view(-1, 1)\n",
        "    num_tokens = src.shape[0]\n",
        "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
        "    tgt_tokens = greedy_decode(\n",
        "        model,  src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX, nvar=nvar).flatten()\n",
        "    return \" \".join(vocab_transform[SRC_LANGUAGE].lookup_tokens(list(tgt_tokens.cpu().numpy()))).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "src = text_transform[SRC_LANGUAGE](\"a man eating beans\").view(-1, 1)\n",
        "src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImUrmzOdBPf7",
        "outputId": "ed9a2e8f-e648-4782-9be1-7abb4fa81797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   2],\n",
              "        [   4],\n",
              "        [   9],\n",
              "        [ 186],\n",
              "        [3865],\n",
              "        [   3]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADrj-M9JjSQR",
        "outputId": "7aea6cca-0e2c-4c52-d1d7-a4b87a480594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " a man eating ice cream cone . \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6990125967948685"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "print(translate(transformer, \"a man eating ice cream.\", 0.1))\n",
        "SNR_to_noise(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "K8eWjHI6O-ga",
        "outputId": "f12ec11f-43be-4137-8b25-717a177f6caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'sentence_transformers'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-36042aa3a3cd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"all-MiniLM-L6-v2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YB1Iu9o0nAJb"
      },
      "outputs": [],
      "source": [
        "sentences1 = [\n",
        "    \"The cat sits outside.\",\n",
        "    \"A man is playing guitar\",\n",
        "    \"A man wearing a coat\",\n",
        "    \"The dog ran very fast\",\n",
        "    \"The boy had a party\",\n",
        "    \"A woman eating a ice cream\"\n",
        "]\n",
        "\n",
        "s = []\n",
        "i = 0.01\n",
        "while(i<1):\n",
        "  #print(i)\n",
        "  sentences2 = [\n",
        "    translate(transformer, \"The cat sits outside.\", i),\n",
        "    translate(transformer, \"A man is playing guitar\", i),\n",
        "    translate(transformer, \"A man wearing a coat\", i),\n",
        "    translate(transformer, \"The dog ran very fast\", i),\n",
        "    translate(transformer, \"The boy had a party\", i),\n",
        "    translate(transformer, \"A woman eating a ice cream\", i)\n",
        "  ]\n",
        "  #print(sentences2[0])\n",
        "  embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
        "  embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
        "  l = []\n",
        "\n",
        "  cosine_scores = Tensor.cpu(util.cos_sim(embeddings1, embeddings2))\n",
        "  for j in range(6):\n",
        "    l.append(cosine_scores[j][j])\n",
        "  s.append(sum(l)/6)\n",
        "  i+=0.05\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "plt.plot(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "zy0DltYPPL6d",
        "outputId": "a113aab7-5006-485e-bf48-b045ccc55b79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb83d5eb520>]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "\n",
        "class NodeTree(object):\n",
        "    def _init_(self, left=None, right=None):\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "\n",
        "    def children(self):\n",
        "        return self.left, self.right\n",
        "\n",
        "    def _str_(self):\n",
        "        return self.left, self.right\n",
        "\n",
        "\n",
        "def huffman_code_tree(node, binString=''):\n",
        "    '''\n",
        "    Function to find Huffman Code\n",
        "    '''\n",
        "    if type(node) is str:\n",
        "        return {node: binString}\n",
        "    (l, r) = node.children()\n",
        "    d = dict()\n",
        "    d.update(huffman_code_tree(l, binString + '0'))\n",
        "    d.update(huffman_code_tree(r, binString + '1'))\n",
        "    return d\n",
        "\n",
        "\n",
        "def make_tree(nodes):\n",
        "    '''\n",
        "    Function to make tree\n",
        "    :param nodes: Nodes\n",
        "    :return: Root of the tree\n",
        "    '''\n",
        "    while len(nodes) > 1:\n",
        "        (key1, c1) = nodes[-1]\n",
        "        (key2, c2) = nodes[-2]\n",
        "        nodes = nodes[:-2]\n",
        "        node = NodeTree()\n",
        "        node.left = key1\n",
        "        node.right = key2\n",
        "        nodes.append((node, c1 + c2))\n",
        "        nodes = sorted(nodes, key=lambda x: x[1], reverse=True)\n",
        "    return nodes[0][0]\n",
        "\n",
        "\n",
        "if (True):\n",
        "    string = 'a man wearing a coat'\n",
        "    freq = dict(Counter(string))\n",
        "    freq = sorted(freq.items(), key=lambda x: x[1], reverse=True)\n",
        "    node = make_tree(freq)\n",
        "    encoding = huffman_code_tree(node)\n",
        "    for i in encoding:\n",
        "        print(f'{i} : {encoding[i]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-IpJqWSQQMk",
        "outputId": "c2c3b1e5-f5bd-4281-fc20-fb80fbc44951"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i : 0000\n",
            "r : 0001\n",
            "c : 0010\n",
            "g : 0011\n",
            "  : 01\n",
            "a : 10\n",
            "m : 1100\n",
            "e : 11010\n",
            "w : 11011\n",
            "t : 11100\n",
            "o : 11101\n",
            "n : 1111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in string:\n",
        "  print(encoding[i],end=\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LftK5M73Q67p",
        "outputId": "45f8d2a2-fafb-4d4e-c276-41cb0c5251b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100111001011110111011110101000010000111100110110010010111011011100"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install reedsolo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_FqcY-mWzOq",
        "outputId": "bad66ff3-9aa9-40b3-97b3-af6227c05cbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting reedsolo\n",
            "  Downloading reedsolo-1.7.0-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: reedsolo\n",
            "Successfully installed reedsolo-1.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import reedsolo as rsc\n",
        "\n",
        "def encoding(per, msg, n, nsym, gen):\n",
        "    time1 = 0\n",
        "    count = 0\n",
        "\n",
        "    rs.init_tables(0x11d)\n",
        "    while time1 < per:\n",
        "        temp = time.time()\n",
        "        s = rs.rs_encode_msg(msg, nsym, gen=gen[nsym])\n",
        "\n",
        "        time1 += time.time() - temp\n",
        "        count += 1\n",
        "    #print(rs.rs_decode(s, nsym, gen=gen[nsym]))\n",
        "    return s\n",
        "\n",
        "def main():\n",
        "    data = b\"a man wearing a coat\" #This data size is 10MB\n",
        "    n = 8\n",
        "    nsym = 3\n",
        "    period = 10\n",
        "\n",
        "\n",
        "    gen = rs.rs_generator_poly_all(n)\n",
        "    encoding(period, data, 8, 3, gen)\n",
        "    return(gen)"
      ],
      "metadata": {
        "id": "lvC9vB8JW0T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from reedsolo import RSCodec, ReedSolomonError\n",
        "rsc = RSCodec(10)\n",
        "a = rsc.encode(b'100111001011110111011110101000010000111100110110010010111011011100')"
      ],
      "metadata": {
        "id": "Gpyf3S6_fclR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6obHx67Kfv35",
        "outputId": "7190970e-85fa-41f2-cf40-d61f2b05389c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bytearray(b'100111001011110111011110101000010000111100110110010010111011011100X\\x9b\\x08\\xbbQX\\x02\\xe4M\\xd3')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = rsc.decode(b'100111001011110111011110101111111111111100110110010010111011011100X\\x9b\\x08\\xbbQX\\x02\\xe4M\\xd3')\n",
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "id": "YBjVBrRhd5xR",
        "outputId": "47360887-b2db-4894-d520-c430b510d42c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ReedSolomonError",
          "evalue": "Too many errors to correct",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mReedSolomonError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-ec4b04ec24ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'100111001011110111011110101111111111111100110110010010111011011100X\\x9b\\x08\\xbbQX\\x02\\xe4M\\xd3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/reedsolo.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, data, nsym, erase_pos, only_erasures)\u001b[0m\n\u001b[1;32m    927\u001b[0m                 \u001b[0merase_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsize\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0merase_pos\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnsize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m             \u001b[0;31m# Decode/repair this chunk!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m             \u001b[0mrmes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrata_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_correct_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfcr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merase_pos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_erasures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0monly_erasures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m             \u001b[0mdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0mdec_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrmes\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mrecc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/reedsolo.py\u001b[0m in \u001b[0;36mrs_correct_msg\u001b[0;34m(msg_in, nsym, fcr, generator, erase_pos, only_erasures)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0mfsynd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_forney_syndromes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merase_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# compute the error locator polynomial using Berlekamp-Massey\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0merr_loc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_find_error_locator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsynd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnsym\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merase_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merase_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0;31m# locate the message errors using Chien search (or bruteforce search)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0merr_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs_find_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_loc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/reedsolo.py\u001b[0m in \u001b[0;36mrs_find_error_locator\u001b[0;34m(synd, nsym, erase_loc, erase_count)\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0merrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_loc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0merrs\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0merase_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0merase_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mnsym\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mReedSolomonError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Too many errors to correct\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merr_loc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mReedSolomonError\u001b[0m: Too many errors to correct"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"100111001011110111011110101000010000111100110110010010111011011100\"\n",
        "length = len(s)\n",
        "import torch\n",
        "noise = torch.rand(1,length)\n",
        "for i in noise[0]:\n",
        "  if(i>0.9):\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYHyp0cqm8wL",
        "outputId": "fb8ba642-2d2a-4bd0-a403-376c13ff42ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.9740)\n",
            "tensor(0.9719)\n",
            "tensor(0.9479)\n",
            "tensor(0.9224)\n",
            "tensor(0.9146)\n",
            "tensor(0.9768)\n",
            "tensor(0.9738)\n",
            "tensor(0.9521)\n",
            "tensor(0.9852)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#len(\"hi\")\n",
        "type(len)\n",
        "del len"
      ],
      "metadata": {
        "id": "rpHQtqodp9_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huffman"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOe3qX94SZOE",
        "outputId": "e0083545-e280-42ff-da00-beb2d3222049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting huffman\n",
            "  Downloading huffman-0.1.2-py2.py3-none-any.whl (4.6 kB)\n",
            "Installing collected packages: huffman\n",
            "Successfully installed huffman-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import heapq\n",
        "import collections\n",
        "import random\n",
        "\n",
        "class HuffmanNode:\n",
        "    def __init__(self, char=None, frequency=None):\n",
        "        self.char = char\n",
        "        self.frequency = frequency\n",
        "        self.left = None\n",
        "        self.right = None\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.frequency < other.frequency\n",
        "\n",
        "def build_huffman_tree(text):\n",
        "    # Calculate character frequencies\n",
        "    char_freq = collections.Counter(text)\n",
        "\n",
        "    # Create Huffman nodes for each character\n",
        "    nodes = [HuffmanNode(char, freq) for char, freq in char_freq.items()]\n",
        "\n",
        "    # Build Huffman tree using priority queue (min heap)\n",
        "    heapq.heapify(nodes)\n",
        "    while len(nodes) > 1:\n",
        "        left = heapq.heappop(nodes)\n",
        "        right = heapq.heappop(nodes)\n",
        "        merged = HuffmanNode(frequency=left.frequency + right.frequency)\n",
        "        merged.left = left\n",
        "        merged.right = right\n",
        "        heapq.heappush(nodes, merged)\n",
        "\n",
        "    return nodes[0]  # Return the root of the Huffman tree\n",
        "\n",
        "def generate_huffman_codes(node, code=\"\", code_dict={}):\n",
        "    if node is None:\n",
        "        return\n",
        "\n",
        "    if node.char is not None:\n",
        "        code_dict[node.char] = code\n",
        "\n",
        "    generate_huffman_codes(node.left, code + \"0\", code_dict)\n",
        "    generate_huffman_codes(node.right, code + \"1\", code_dict)\n",
        "\n",
        "def encode_text(text, code_dict):\n",
        "    return \"\".join(code_dict[char] for char in text)\n",
        "\n",
        "def decode_text(encoded_text, root):\n",
        "    decoded_text = \"\"\n",
        "    current = root\n",
        "    for bit in encoded_text:\n",
        "        if bit == \"0\":\n",
        "            current = current.left\n",
        "        else:\n",
        "            current = current.right\n",
        "\n",
        "        if current.char is not None:\n",
        "            decoded_text += current.char\n",
        "            current = root\n",
        "\n",
        "    return decoded_text\n",
        "\n",
        "def add_noise(encoded_text, snr):\n",
        "    signal_power = len(encoded_text)\n",
        "    noise_power = signal_power / (10 ** (snr / 10))  # Calculate noise power based on SNR\n",
        "    noise_indices = random.sample(range(signal_power), int(noise_power))\n",
        "\n",
        "    encoded_list = list(encoded_text)\n",
        "    for index in noise_indices:\n",
        "        encoded_list[index] = '0' if encoded_list[index] == '1' else '1'\n",
        "\n",
        "    return ''.join(encoded_list)\n",
        "\n",
        "# Example usage\n",
        "text_to_encode = \"hello world\"\n",
        "\n",
        "# Build Huffman tree and generate codes\n",
        "root_node = build_huffman_tree(text_to_encode)\n",
        "code_dict = {}\n",
        "generate_huffman_codes(root_node, code_dict=code_dict)\n",
        "\n",
        "# Encode the text using Huffman codes\n",
        "encoded_text = encode_text(text_to_encode, code_dict)\n",
        "print(\"Encoded Text:\", encoded_text)\n",
        "print(\"Huffman Codes:\", code_dict)\n",
        "\n",
        "# Decode the encoded text using the Huffman tree\n",
        "decoded_text = decode_text(encoded_text, root_node)\n",
        "print(\"Decoded Text:\", decoded_text)\n",
        "\n",
        "# Add noise to the encoded text based on SNR (Signal-to-Noise Ratio)\n",
        "snr = 10  # Example SNR in dB\n",
        "noisy_encoded_text = add_noise(encoded_text, snr)\n",
        "print(\"Noisy Encoded Text:\", noisy_encoded_text)\n",
        "print(decode_text(noisy_encoded_text, root_node))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UwgIdZAUmfk",
        "outputId": "2d33440a-e2db-454a-e13d-8c06312c31d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Text: 11100001010110111101111001010001\n",
            "Huffman Codes: {'e': '000', 'd': '001', 'r': '010', 'w': '011', 'l': '10', 'o': '110', 'h': '1110', ' ': '1111'}\n",
            "Decoded Text: hello world\n",
            "Noisy Encoded Text: 11100000010110101101111001010101\n",
            "hedwro drl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_encode = \"a man wearing a coat\"\n",
        "\n",
        "# Build Huffman tree and generate codes\n",
        "root_node = build_huffman_tree(text_to_encode)\n",
        "code_dict = {}\n",
        "generate_huffman_codes(root_node, code_dict=code_dict)\n",
        "\n",
        "# Encode the text using Huffman codes\n",
        "encoded_text = encode_text(text_to_encode, code_dict)\n",
        "print(\"Encoded Text:\", encoded_text)\n",
        "print(\"Huffman Codes:\", code_dict)\n",
        "\n",
        "# Decode the encoded text using the Huffman tree\n",
        "decoded_text = decode_text(encoded_text, root_node)\n",
        "print(\"Decoded Text:\", decoded_text)\n",
        "\n",
        "# Add noise to the encoded text based on SNR (Signal-to-Noise Ratio)\n",
        "snr = 5  # Example SNR in dB\n",
        "noisy_encoded_text = add_noise(encoded_text, snr)\n",
        "print(\"Noisy Encoded Text:\", noisy_encoded_text)\n",
        "print(decode_text(noisy_encoded_text, root_node))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uEScwCSdcIo",
        "outputId": "421b5c02-6a11-4cfb-e4c2-25b1fa431556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded Text: 100111011100010100011111110110101100001111010110011110000001011110\n",
            "Huffman Codes: {'o': '0000', 'w': '0001', 'n': '001', ' ': '01', 'a': '10', 'i': '1100', 'r': '11010', 'm': '11011', 'c': '11100', 'g': '11101', 't': '11110', 'e': '11111'}\n",
            "Decoded Text: a man wearing a coat\n",
            "Noisy Encoded Text: 010101011101011101111111010010110001101101010110111100000001001000\n",
            "    rgeaa  anaramio n\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snr = 200  # Example SNR in dB\n",
        "noisy_encoded_text = add_noise(encoded_text, snr)\n",
        "print(\"Noisy Encoded Text:\", noisy_encoded_text)\n",
        "print(decode_text(noisy_encoded_text, root_node))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYP0M_oOePRv",
        "outputId": "c3c9249b-1b84-4faa-f953-1691067f9209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Noisy Encoded Text: 100111011100010100011111110110101100001111010110011110000001011110\n",
            "a man wearing a coat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1\n",
        "while(i<30):\n",
        "  noisy_encoded_text = add_noise(encoded_text, i)\n",
        "  a = (decode_text(noisy_encoded_text, root_node))\n",
        "  embeddings1 = model.encode(text_to_encode, convert_to_tensor=True)\n",
        "  embeddings2 = model.encode(a, convert_to_tensor=True)\n",
        "  cosine_scores = Tensor.cpu(util.cos_sim(embeddings1, embeddings2))\n",
        "  l.append(cosine_scores)\n",
        "  i += 1\n",
        "plt.plot(l)\n"
      ],
      "metadata": {
        "id": "fjE8Q09Me9tW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}